from model import Profile
import numpy as np
import librosa
from moviepy.editor import *
import os
from PIL import Image
from moviepy.editor import TextClip, VideoClip
from moviepy.video.fx.all import fadein, fadeout
from moviepy.editor import ImageClip
from PIL import Image, ImageDraw, ImageFont

def create_text_image(text, font_size, color, bg_color, size):
# img = create_text_image("Your Text Here", 50, "white", "black", (800, 600))
# img.save("text_image.png")
# clip = ImageClip("text_image.png").set_duration(5)    
    
    img = Image.new('RGB', size, bg_color)
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype('arial.ttf', font_size)
    w, h = draw.textsize(text, font=font)
    draw.text(((size[0]-w)/2, (size[1]-h)/2), text, fill=color, font=font)
    return img

from moviepy.editor import TextClip, VideoClip
from moviepy.video.fx.all import fadein, fadeout

def create_text_clip(text, duration, start_time=0, end_time=None,
                     position=(50, 50), position_units='percent',
                     font='Arial', font_size=50, font_color='white',
                     stroke_color='black', stroke_width=2,
                     fade_duration=0.5,
                     video_size=(1280, 720)):
    """
    Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ»Ð¸Ð¿ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð½Ð° Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ð¾Ð¼ Ñ„Ð¾Ð½Ðµ.

    ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:
    - text (str): Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.
    - duration (float): Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÐºÐ»Ð¸Ð¿Ð° Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….
    - start_time (float): Ð’Ñ€ÐµÐ¼Ñ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….
    - end_time (float): Ð’Ñ€ÐµÐ¼Ñ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…. Ð•ÑÐ»Ð¸ None, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ start_time + duration.
    - position (tuple): ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° (x, y). Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð°Ñ… Ð¸Ð»Ð¸ Ð¿Ð¸ÐºÑÐµÐ»ÑÑ…, Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ position_units.
    - position_units (str): Ð•Ð´Ð¸Ð½Ð¸Ñ†Ñ‹ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ ('percent' Ð¸Ð»Ð¸ 'pixels').
    - font (str): ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑˆÑ€Ð¸Ñ„Ñ‚Ð°.
    - font_size (int): Ð Ð°Ð·Ð¼ÐµÑ€ ÑˆÑ€Ð¸Ñ„Ñ‚Ð°.
    - font_color (str Ð¸Ð»Ð¸ tuple): Ð¦Ð²ÐµÑ‚ ÑˆÑ€Ð¸Ñ„Ñ‚Ð°.
    - stroke_color (str Ð¸Ð»Ð¸ tuple): Ð¦Ð²ÐµÑ‚ Ð¾Ð±Ð²Ð¾Ð´ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°.
    - stroke_width (int): Ð¢Ð¾Ð»Ñ‰Ð¸Ð½Ð° Ð¾Ð±Ð²Ð¾Ð´ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°.
    - fade_duration (float): Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÑ„Ñ„ÐµÐºÑ‚Ð¾Ð² Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¸ Ð¸ÑÑ‡ÐµÐ·Ð½Ð¾Ð²ÐµÐ½Ð¸Ñ Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….
    - video_size (tuple): Ð Ð°Ð·Ð¼ÐµÑ€ Ð²Ð¸Ð´ÐµÐ¾ (width, height) Ð´Ð»Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð² Ð¿Ð¸ÐºÑÐµÐ»ÑÑ….

    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - text_clip (VideoClip): ÐšÐ»Ð¸Ð¿ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð¸ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¼ Ñ„Ð¾Ð½Ð¾Ð¼.
    """
    if end_time is None:
        end_time = start_time + duration

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÐºÐ»Ð¸Ð¿
    text_clip = TextClip(text,
                         fontsize=font_size,
                         font=font,
                         color=font_color,
                         stroke_color=stroke_color,
                         stroke_width=stroke_width,
                         method='caption',
                         size=None)

    # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ
    text_clip = text_clip.set_duration(end_time - start_time)

    # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹ Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¸ Ð¸ÑÑ‡ÐµÐ·Ð½Ð¾Ð²ÐµÐ½Ð¸Ñ
    if fade_duration > 0:
        text_clip = text_clip.fx(fadein, fade_duration).fx(fadeout, fade_duration)

    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ Ð¸Ð· Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð¿Ð¸ÐºÑÐµÐ»Ð¸, ÐµÑÐ»Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾
    if position_units == 'percent':
        x = int(position[0] * video_size[0] / 100)
        y = int(position[1] * video_size[1] / 100)
        pos = (x, y)
    else:
        pos = position

    text_clip = text_clip.set_position(pos)

    # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    text_clip = text_clip.set_start(start_time)

    return text_clip


def create_text_clip_pil(text, duration, start_time=0, end_time=None,
                         position=(50, 50), position_units='percent',
                         font='Arial', font_size=50, font_color='white',
                         stroke_color='black', stroke_width=2,
                         fade_duration=0.5,
                         video_size=(1280, 720)):
    """
    Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ»Ð¸Ð¿ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð½Ð° Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ð¾Ð¼ Ñ„Ð¾Ð½Ðµ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ PIL.

    ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:
    - Ñ‚Ðµ Ð¶Ðµ, Ñ‡Ñ‚Ð¾ Ð¸ Ñƒ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ create_text_clip.

    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - text_clip (VideoClip): ÐšÐ»Ð¸Ð¿ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð¸ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¼ Ñ„Ð¾Ð½Ð¾Ð¼.
    """
    if end_time is None:
        end_time = start_time + duration

    # Ð Ð°Ð·Ð¼ÐµÑ€ Ð²Ð¸Ð´ÐµÐ¾
    width, height = video_size

    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑˆÑ€Ð¸Ñ„Ñ‚
    try:
        font_obj = ImageFont.truetype(font, font_size)
    except IOError:
        font_obj = ImageFont.load_default()

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÐºÐ°Ð´Ñ€Ð¾Ð²
    def make_frame(t):
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ
        img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)

        # Ð˜Ð·Ð¼ÐµÑ€ÑÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ‚ÐµÐºÑÑ‚Ð°
        text_size = draw.textsize(text, font=font_obj, stroke_width=stroke_width)

        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ Ð¸Ð· Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð¿Ð¸ÐºÑÐµÐ»Ð¸, ÐµÑÐ»Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾
        if position_units == 'percent':
            x = int(position[0] * width / 100)
            y = int(position[1] * height / 100)
        else:
            x, y = position

        # Ð¦ÐµÐ½Ñ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ð¾Ð¹ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸
        text_x = x - text_size[0] // 2
        text_y = y - text_size[1] // 2

        # Ð Ð¸ÑÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ñ Ð¾Ð±Ð²Ð¾Ð´ÐºÐ¾Ð¹
        draw.text((text_x, text_y), text, font=font_obj, fill=font_color,
                  stroke_width=stroke_width, stroke_fill=stroke_color)

        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² Ð¼Ð°ÑÑÐ¸Ð² numpy
        frame = np.array(img)

        return frame

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾ ÐºÐ»Ð¸Ð¿
    text_clip = VideoClip(make_frame, duration=end_time - start_time)

    # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹ Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¸ Ð¸ÑÑ‡ÐµÐ·Ð½Ð¾Ð²ÐµÐ½Ð¸Ñ
    if fade_duration > 0:
        text_clip = text_clip.fx(fadein, fade_duration).fx(fadeout, fade_duration)

    # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    text_clip = text_clip.set_start(start_time)

    return text_clip

# ÐŸÐ°Ð¿ÐºÐ° ÑÐ¾ ÑˆÑ€Ð¸Ñ„Ñ‚Ð°Ð¼Ð¸ Ð² Windows
FONTS_FOLDERS = ["C:\\Windows\\Fonts"]  # ÐœÐ¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°Ð¿ÐºÐ¸ Ð¿Ð¾ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸

# python -c "import tools; tools.find_fonts('Arial')" 
def find_fonts(keyword=None):
    found_fonts = []
    
    # ÐŸÐµÑ€ÐµÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸ ÑÐ¾ ÑˆÑ€Ð¸Ñ„Ñ‚Ð°Ð¼Ð¸
    for folder in FONTS_FOLDERS:
        # ÐŸÐµÑ€ÐµÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐµ
        for font_file in os.listdir(folder):
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ñ„Ð°Ð¹Ð» ÑˆÑ€Ð¸Ñ„Ñ‚Ð¾Ð¼
            if font_file.endswith(('.ttf', '.otf')):
                # Ð•ÑÐ»Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½Ð¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾, Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ÑÑ Ð»Ð¸ Ð¾Ð½Ð¾ Ð² Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°
                if keyword is None or keyword.lower() in font_file.lower():
                    font_path = os.path.join(folder, font_file)
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑˆÑ€Ð¸Ñ„Ñ‚Ðµ Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐº
                    font_info = {
                        'font_file': font_file,
                        'font_path': font_path,
                        'usable_in_moviepy': True,  # Ð”Ð»Ñ MoviePy Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ
                        'usable_in_pil': True       # Ð”Ð»Ñ PIL Ð½ÑƒÐ¶ÐµÐ½ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ
                    }
                    found_fonts.append(font_info)
    
    # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    if found_fonts:
        for font in found_fonts:
            print(f"ÐÐ°Ð¹Ð´ÐµÐ½ ÑˆÑ€Ð¸Ñ„Ñ‚: {font['font_file']}")
            print(f"ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ: {font['font_path']}")
            print(f"ÐœÐ¾Ð¶ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ñ MoviePy: {'Ð”Ð°' if font['usable_in_moviepy'] else 'ÐÐµÑ‚'}")
            print(f"ÐœÐ¾Ð¶ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ñ PIL: {'Ð”Ð°' if font['usable_in_pil'] else 'ÐÐµÑ‚'}")
            print("-" * 40)
    else:
        print("Ð¨Ñ€Ð¸Ñ„Ñ‚Ñ‹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹.")

def get_audio_file(folder):
    # ÐŸÑƒÑ‚ÑŒ Ðº Ð°ÑƒÐ´Ð¸Ð¾-Ñ„Ð°Ð¹Ð»Ñƒ
    audio_file = [os.path.join(folder, music) \
                    for music in os.listdir(folder) if music.endswith(('.mp3'))][0] # os.path.join(folder, "music.mp3")

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾-Ñ„Ð°Ð¹Ð»
    if not os.path.isfile(audio_file):
        print(f"âŒAudio file not found in {folder}")
        return
    
    return audio_file    

def get_directory_from_path(file_path):
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÑƒÑ‚ÑŒ Ðº Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
    directory_path = os.path.dirname(file_path)
    return directory_path

def get_filename_without_extension(file_path):
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼
    file_name_with_extension = os.path.basename(file_path)
    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ
    file_name_without_extension = os.path.splitext(file_name_with_extension)[0]
    return file_name_without_extension

def suggest_frequency_bands(audio_file, num_bands=4, sr=None, n_fft=2048, hop_length=None):
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð°Ð¹Ð»
    y, sr = librosa.load(audio_file, sr=sr, mono=True)

    if hop_length is None:
        hop_length = n_fft // 4

    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñƒ
    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
    frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)

    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð°Ð¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ñ‹ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ (ÑÐ¿ÐµÐºÑ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð»ÑŽÐºÑ)
    spectral_flux = np.var(S, axis=1)

    # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ð¹ ÑÐ¿ÐµÐºÑ‚Ñ€ Ð½Ð° Ñ€Ð°Ð²Ð½Ñ‹Ðµ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñ‹
    num_freqs = len(frequencies)
    freq_bins = np.linspace(frequencies[0], frequencies[-1], num=500)

    # Ð¡ÑƒÐ¼Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¿ÐµÐºÑ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð»ÑŽÐºÑ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ð¾Ð¼ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ðµ
    flux_per_band = []
    for i in range(len(freq_bins) - 1):
        freq_mask = (frequencies >= freq_bins[i]) & (frequencies < freq_bins[i+1])
        if np.any(freq_mask):
            flux = np.sum(spectral_flux[freq_mask])
            flux_per_band.append((flux, freq_bins[i], freq_bins[i+1]))

    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñ‹ Ð¿Ð¾ Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð½Ðµ ÑÐ¿ÐµÐºÑ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ„Ð»ÑŽÐºÑÐ° (Ð¸Ð·Ð¼ÐµÐ½Ñ‡Ð¸Ð²Ð¾ÑÑ‚Ð¸)
    flux_per_band.sort(reverse=True, key=lambda x: x[0])

    # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚Ð¾Ð¿ `num_bands` Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð¾Ð²
    top_bands = flux_per_band[:num_bands]

    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñ‹ Ð¿Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°Ð½Ð¸ÑŽ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹
    top_bands.sort(key=lambda x: x[1])

    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð¾Ð²
    suggested_bands = [(round(band[1]), round(band[2])) for band in top_bands]

    print("ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÐ¼Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð½Ñ‹Ðµ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñ‹:")
    for idx, band in enumerate(suggested_bands):
        print(f"Ð”Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ {idx+1}: {band[0]} - {band[1]} Ð“Ñ†")

    return suggested_bands


def merge_videos_with_audio(video_files, audio_file, output_file, profile: Profile, threads=4):
    """
    ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ðº Ð½Ð¸Ð¼ Ð°ÑƒÐ´Ð¸Ð¾, Ð·Ð°Ñ‚ÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ñ„Ð°Ð¹Ð».
    
    :param video_files: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿ÑƒÑ‚ÐµÐ¹ Ðº Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ð°Ð¼ (Ð±ÐµÐ· Ð°ÑƒÐ´Ð¸Ð¾).
    :param audio_file: ÐŸÑƒÑ‚ÑŒ Ðº Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»Ñƒ (MP3).
    :param output_file: ÐŸÑƒÑ‚ÑŒ Ðº Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ñƒ.
    """
    print(f"ðŸš€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ {len(video_files)} Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ð¾Ð².")
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ñ‹
    clips = []
    for idx, file in enumerate(video_files):
        print(f"ðŸ“‚ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ð° {idx + 1}/{len(video_files)}: {file}")
        clip = VideoFileClip(file)
        clips.append(clip)
    
    print("âœ… Ð’ÑÐµ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹.")

    # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ñ‹
    print("ðŸ”— ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð»Ð¾Ð²...")
    final_clip = concatenate_videoclips(clips, method="compose")
    print("ðŸŽ¬ Ð’Ð¸Ð´ÐµÐ¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¾.")

    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð°Ð¹Ð»
    print(f"ðŸŽµ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»Ð°: {audio_file}")
    audio = AudioFileClip(audio_file)
    print("âœ… ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½.")

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ðº Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ð²Ð¸Ð´ÐµÐ¾
    print("ðŸŽ¶ Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°ÑƒÐ´Ð¸Ð¾ Ðº Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð½Ð¾Ð¼Ñƒ Ð²Ð¸Ð´ÐµÐ¾...")
    final_clip = final_clip.set_audio(audio)
    print("âœ… ÐÑƒÐ´Ð¸Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾ Ðº Ð²Ð¸Ð´ÐµÐ¾.")

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
    print(f"ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°: {output_file}")
    final_clip.write_videofile(output_file, codec=profile.codec, preset=profile.preset, threads=threads)
    print(f"ðŸŽ‰ Ð¤Ð°Ð¹Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {output_file}")

        # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
    for file in video_files:
        if os.path.exists(file):
            os.remove(file)
            print(f"Ð£Ð´Ð°Ð»Ñ‘Ð½ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»: {file}")


def merge_videos(output_file, video_files):
    
    # folder = 'path/to/your/videos'
    # video_files = sorted([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.mp4')])

    # # Output file path
    # output_file = os.path.join(folder, "merged_output_video.mp4")
    
    # Load all video clips
    clips = [VideoFileClip(file) for file in video_files]
    
    # Concatenate all clips into one
    final_clip = concatenate_videoclips(clips, method="compose")
    
    # Write the result to a file
    final_clip.write_videofile(output_file, codec="libx264", threads=4)


def get_segment_duration(total_duration, segment_number, total_segments):
    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°
    segment_length = total_duration // total_segments
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ð¸ ÐºÐ¾Ð½ÐµÑ† ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°
    start_time = segment_number * segment_length
    end_time = start_time + segment_length
    
    # Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚, ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ
    if segment_number == total_segments + 1:
        end_time = total_duration - 1
    
    return start_time, end_time

def add_gif(gif_file, audio_duration, slideshow):
    if gif_file and os.path.isfile(gif_file):
        print("GIF: âœ”Gif file found")

        has_mask = False # has_transparency(gif_file)
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ GIF Ð¸ Ð·Ð°Ñ†Ð¸ÐºÐ»Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð° Ð²ÑÑŽ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾
        gif_clip = (VideoFileClip(gif_file, has_mask)
                    .loop(duration=(14.0 * 2.0)) # two times # duration=audio_duration)
                    # .resize(0.5)  # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ (0.5 = 50% Ð¾Ñ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°)
                    .set_position(("left", "bottom")))  # ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ (Ð¼Ð¾Ð¶Ð½Ð¾ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð½Ð° Ð½ÑƒÐ¶Ð½ÑƒÑŽ)

        # Ð”ÐµÐ»Ð°ÐµÐ¼ Ñ„Ð¾Ð½ GIF Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¼ (ÑƒÐ´Ð°Ð»ÑÐµÐ¼ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚)
        gif_clip = gif_clip.fx(vfx.mask_color, color=[0, 0, 0], thr=100, s=5)

        inspect_clip("gif_clip", gif_clip)

        # ÐÐ°ÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÐµÐ¼ GIF Ð¿Ð¾Ð²ÐµÑ€Ñ… ÑÐ»Ð°Ð¹Ð´-ÑˆÐ¾Ñƒ
        final_video = CompositeVideoClip([slideshow, gif_clip])
    else:
        final_video = slideshow
    return final_video

def create_slideshow_with_fade_OLD(images, audio_duration, image_duration=2, fade_duration=0.1):
    image_clips = []
    
    # Create individual image clips with fade in and fade out
    for img in images:
        clip = ImageClip(img).set_duration(image_duration)
        # Apply fade in and fade out effect
        clip = clip.crossfadein(fade_duration).crossfadeout(fade_duration)
        image_clips.append(clip)

    # Concatenate images to form a slideshow
    slideshow = concatenate_videoclips(image_clips, method="compose")

    # Loop the slideshow to match the audio duration
    print(f"SLIDESðŸ–¼ :: ðŸ”Looping at âŒ›duration: {audio_duration}")
    looped_slideshow = slideshow.loop(duration=audio_duration)

    return looped_slideshow

from moviepy.editor import ImageClip, concatenate_videoclips

def create_slideshow_with_fade(images, audio_duration, image_duration=2, fade_duration=0.1):
    image_clips = []
    
    print(f"SLIDESðŸ–¼ :: Total images: {len(images)} :: ðŸ”Looping at âŒ›duration: {audio_duration} secs")
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ»Ð¸Ð¿Ñ‹ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð°Ð¼Ð¸ Ð·Ð°Ñ‚ÐµÐ¼Ð½ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ñ
    for img in images:
        clip = ImageClip(img).set_duration(image_duration)
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹ Ð¿Ð»Ð°Ð²Ð½Ð¾Ð³Ð¾ Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¸ Ð¸ÑÑ‡ÐµÐ·Ð½Ð¾Ð²ÐµÐ½Ð¸Ñ
        clip = clip.fadein(fade_duration).fadeout(fade_duration)
        image_clips.append(clip)
    
    # ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² ÑÐ»Ð°Ð¹Ð´ÑˆÐ¾Ñƒ
    slideshow = concatenate_videoclips(image_clips, method="compose")
    
    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ»Ð°Ð¹Ð´ÑˆÐ¾Ñƒ
    slideshow_duration = slideshow.duration
    
    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð· Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚ÑŒ ÑÐ»Ð°Ð¹Ð´ÑˆÐ¾Ñƒ
    num_repeats = int(audio_duration // slideshow_duration) + 1
    
    # Ð Ð°Ð·Ð¼Ð½Ð¾Ð¶Ð°ÐµÐ¼ Ð¼Ð°ÑÑÐ¸Ð² ÐºÐ»Ð¸Ð¿Ð¾Ð²
    replicated_clips = image_clips * num_repeats
    print(f"SLIDESðŸ–¼ :: Replicated images: {len(replicated_clips)} :: ðŸ”Repeated: {num_repeats} times")
    
    # ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð¸Ñ€ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð¼Ð½Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ»Ð¸Ð¿Ñ‹ Ð² Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ»Ð°Ð¹Ð´ÑˆÐ¾Ñƒ
    full_slideshow = concatenate_videoclips(replicated_clips, method="compose")
    
    # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ ÑÐ»Ð°Ð¹Ð´ÑˆÐ¾Ñƒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ð½Ð¾ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ð»Ð¾ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð°ÑƒÐ´Ð¸Ð¾
    final_slideshow = full_slideshow.subclip(0, audio_duration)
    
    return final_slideshow



def inspect_clip(name, clip, debug=False):
    if not debug:
        return
    
    # Get the size (resolution) of the clip
    print(f"===== Inspect clip: {name} ========")
    size = clip.size
    print(f"Size (width, height): {size}")
    
    # Get the duration of the clip
    duration = clip.duration
    print(f"Duration: {duration} seconds")
    
    # Check if the clip has an alpha mask (transparency)
    has_transparency = clip.mask is not None
    print(f"Has transparency (alpha channel): {has_transparency}")
    
    # Get the number of color channels by inspecting a frame
    frame = clip.get_frame(0)  # Get the first frame of the clip
    num_channels = frame.shape[2] if len(frame.shape) == 3 else 1  # Check if the frame has color channels
    print(f"Number of color channels: {num_channels} (â„¹: 3 for RGB, 4 for RGBA)")
    
    # Print if the clip has transparency based on number of channels
    if num_channels == 4:
        print("This clip is RGBA (has transparency).")
    else:
        print("This clip is RGB (no transparency).")
    print("==============================")

# Example usage with a clip:
# Assuming you have a clip object
# inspect_clip(clip)


def has_transparency(gif_path):
    img = Image.open(gif_path)
    if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):
        return True
    return False


# # Assuming 'final_video' is your video clip and 'audio_duration' is the duration of the audio
# text = "Ð’ÐžÐ¢ Ð‘Ð« Ð‘Ð«Ð›Ð"  # The text you want to add

# # Add text overlay to the video
# final_video_with_text = add_text_overlay(final_video, text, duration=audio_duration)

# # Save the final video with text
# final_video_with_text.write_videofile("output_with_text.mp4", fps=24)

def add_text_overlay(video_clip, text, duration, fontsize=50, color='white', transparency=0.6):
    # Create the text clip
    text_clip = (TextClip(text, fontsize=fontsize, color=color, font='Arial-Bold')
                 .set_duration(duration)
                 .set_position(('center', 'bottom'))  # Position at the center bottom of the video
                 .set_opacity(transparency))  # Set transparency

    # Overlay the text on the video
    video_with_text = CompositeVideoClip([video_clip, text_clip])

    return video_with_text