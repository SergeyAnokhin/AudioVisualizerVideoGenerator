from console_tools import ice, prefix_color
from model import Profile
import numpy as np
import librosa
from moviepy.editor import *
import os
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import TextClip, VideoClip
from moviepy.video.fx.all import fadein, fadeout
from moviepy.editor import ImageClip, concatenate_videoclips


def create_text_image(text, font_size, color, bg_color, size):
    # img = create_text_image("Your Text Here", 50, "white", "black", (800, 600))
    # img.save("text_image.png")
    # clip = ImageClip("text_image.png").set_duration(5)

    img = Image.new("RGB", size, bg_color)
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype("arial.ttf", font_size)
    w, h = draw.textsize(text, font=font)
    draw.text(((size[0] - w) / 2, (size[1] - h) / 2), text, fill=color, font=font)
    return img


def create_text_clip(
    text,
    duration,
    start_time=0,
    end_time=None,
    position=(50, 50),
    position_units="percent",
    font="Arial",
    font_size=50,
    font_color="white",
    stroke_color="black",
    stroke_width=2,
    fade_duration=0.5,
    video_size=(1280, 720),
):
    """
    –°–æ–∑–¥–∞–µ—Ç –≤–∏–¥–µ–æ–∫–ª–∏–ø —Å —Ç–µ–∫—Å—Ç–æ–º –Ω–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–º —Ñ–æ–Ω–µ.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - text (str): –¢–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    - duration (float): –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–ø–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö.
    - start_time (float): –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö.
    - end_time (float): –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö. –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è start_time + duration.
    - position (tuple): –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (x, y). –ó–Ω–∞—á–µ–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –∏–ª–∏ –ø–∏–∫—Å–µ–ª—è—Ö, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç position_units.
    - position_units (str): –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏ ('percent' –∏–ª–∏ 'pixels').
    - font (str): –ù–∞–∑–≤–∞–Ω–∏–µ —à—Ä–∏—Ñ—Ç–∞.
    - font_size (int): –†–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞.
    - font_color (str –∏–ª–∏ tuple): –¶–≤–µ—Ç —à—Ä–∏—Ñ—Ç–∞.
    - stroke_color (str –∏–ª–∏ tuple): –¶–≤–µ—Ç –æ–±–≤–æ–¥–∫–∏ —Ç–µ–∫—Å—Ç–∞.
    - stroke_width (int): –¢–æ–ª—â–∏–Ω–∞ –æ–±–≤–æ–¥–∫–∏ —Ç–µ–∫—Å—Ç–∞.
    - fade_duration (float): –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –ø–æ—è–≤–ª–µ–Ω–∏—è –∏ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö.
    - video_size (tuple): –†–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ (width, height) –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø–æ–∑–∏—Ü–∏–∏ –≤ –ø–∏–∫—Å–µ–ª—è—Ö.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - text_clip (VideoClip): –ö–ª–∏–ø —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º.
    """
    if end_time is None:
        end_time = start_time + duration

    # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–ª–∏–ø
    text_clip = TextClip(
        text,
        fontsize=font_size,
        font=font,
        color=font_color,
        stroke_color=stroke_color,
        stroke_width=stroke_width,
        method="caption",
        size=None,
    )

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    text_clip = text_clip.set_duration(end_time - start_time)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –ø–æ—è–≤–ª–µ–Ω–∏—è –∏ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è
    if fade_duration > 0:
        text_clip = text_clip.fx(fadein, fade_duration).fx(fadeout, fade_duration)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–∑–∏—Ü–∏—é –∏–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –≤ –ø–∏–∫—Å–µ–ª–∏, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    if position_units == "percent":
        x = int(position[0] * video_size[0] / 100)
        y = int(position[1] * video_size[1] / 100)
        pos = (x, y)
    else:
        pos = position

    text_clip = text_clip.set_position(pos)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text_clip = text_clip.set_start(start_time)

    return text_clip


def create_text_clip_pil(
    text,
    duration,
    start_time=0,
    end_time=None,
    position=(50, 50),
    position_units="percent",
    font="Arial",
    font_size=50,
    font_color="white",
    stroke_color="black",
    stroke_width=2,
    fade_duration=0.5,
    video_size=(1280, 720),
):
    """
    –°–æ–∑–¥–∞–µ—Ç –≤–∏–¥–µ–æ–∫–ª–∏–ø —Å —Ç–µ–∫—Å—Ç–æ–º –Ω–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–º —Ñ–æ–Ω–µ, –∏—Å–ø–æ–ª—å–∑—É—è PIL.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - —Ç–µ –∂–µ, —á—Ç–æ –∏ —É —Ñ—É–Ω–∫—Ü–∏–∏ create_text_clip.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - text_clip (VideoClip): –ö–ª–∏–ø —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º.
    """
    if end_time is None:
        end_time = start_time + duration

    # –†–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ
    width, height = video_size

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —à—Ä–∏—Ñ—Ç
    try:
        font_obj = ImageFont.truetype(font, font_size)
    except IOError:
        font_obj = ImageFont.load_default()

    # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞–¥—Ä–æ–≤
    def make_frame(t):
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–∑—Ä–∞—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)

        # –ò–∑–º–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
        text_size = draw.textsize(text, font=font_obj, stroke_width=stroke_width)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–∑–∏—Ü–∏—é –∏–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –≤ –ø–∏–∫—Å–µ–ª–∏, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        if position_units == "percent":
            x = int(position[0] * width / 100)
            y = int(position[1] * height / 100)
        else:
            x, y = position

        # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞–Ω–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
        text_x = x - text_size[0] // 2
        text_y = y - text_size[1] // 2

        # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç —Å –æ–±–≤–æ–¥–∫–æ–π
        draw.text(
            (text_x, text_y),
            text,
            font=font_obj,
            fill=font_color,
            stroke_width=stroke_width,
            stroke_fill=stroke_color,
        )

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –º–∞—Å—Å–∏–≤ numpy
        frame = np.array(img)

        return frame

    # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ –∫–ª–∏–ø
    text_clip = VideoClip(make_frame, duration=end_time - start_time)

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –ø–æ—è–≤–ª–µ–Ω–∏—è –∏ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è
    if fade_duration > 0:
        text_clip = text_clip.fx(fadein, fade_duration).fx(fadeout, fade_duration)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text_clip = text_clip.set_start(start_time)

    return text_clip


# –ü–∞–ø–∫–∞ —Å–æ —à—Ä–∏—Ñ—Ç–∞–º–∏ –≤ Windows
FONTS_FOLDERS = ["C:\\Windows\\Fonts"]  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –ø–∞–ø–∫–∏ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏


# python -c "import tools; tools.find_fonts('Arial')"
def find_fonts(keyword=None):
    found_fonts = []

    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–∞–ø–∫–∏ —Å–æ —à—Ä–∏—Ñ—Ç–∞–º–∏
    for folder in FONTS_FOLDERS:
        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
        for font_file in os.listdir(folder):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —à—Ä–∏—Ñ—Ç–æ–º
            if font_file.endswith((".ttf", ".otf")):
                # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –æ–Ω–æ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞
                if keyword is None or keyword.lower() in font_file.lower():
                    font_path = os.path.join(folder, font_file)
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à—Ä–∏—Ñ—Ç–µ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫
                    font_info = {
                        "font_file": font_file,
                        "font_path": font_path,
                        "usable_in_moviepy": True,  # –î–ª—è MoviePy –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        "usable_in_pil": True,  # –î–ª—è PIL –Ω—É–∂–µ–Ω –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
                    }
                    found_fonts.append(font_info)

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if found_fonts:
        for font in found_fonts:
            print(f"–ù–∞–π–¥–µ–Ω —à—Ä–∏—Ñ—Ç: {font['font_file']}")
            print(f"–ü–æ–ª–Ω—ã–π –ø—É—Ç—å: {font['font_path']}")
            print(
                f"–ú–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å MoviePy: {'–î–∞' if font['usable_in_moviepy'] else '–ù–µ—Ç'}"
            )
            print(
                f"–ú–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å PIL: {'–î–∞' if font['usable_in_pil'] else '–ù–µ—Ç'}"
            )
            print("-" * 40)
    else:
        print("–®—Ä–∏—Ñ—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")


def get_audio_file(folder):
    # –ü—É—Ç—å –∫ –∞—É–¥–∏–æ-—Ñ–∞–π–ª—É
    audio_file = [
        os.path.join(folder, music)
        for music in os.listdir(folder)
        if music.endswith((".mp3"))
    ][
        0
    ]  # os.path.join(folder, "music.mp3")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∞—É–¥–∏–æ-—Ñ–∞–π–ª
    if not os.path.isfile(audio_file):
        print(f"‚ùåAudio file not found in {folder}")
        return

    return audio_file


def get_directory_from_path(file_path):
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    directory_path = os.path.dirname(file_path)
    return directory_path


def get_filename_without_extension(file_path):
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
    file_name_with_extension = os.path.basename(file_path)
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    file_name_without_extension = os.path.splitext(file_name_with_extension)[0]
    return file_name_without_extension


def suggest_frequency_bands(
    audio_file, num_bands=4, sr=None, n_fft=2048, hop_length=None
):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
    y, sr = librosa.load(audio_file, sr=sr, mono=True)

    if hop_length is None:
        hop_length = n_fft // 4

    # –í—ã—á–∏—Å–ª—è–µ–º —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))

    # –ü–æ–ª—É—á–∞–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)

    # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∞–º–ø–ª–∏—Ç—É–¥—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–æ—Ç—ã (—Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–ª—é–∫—Å)
    spectral_flux = np.var(S, axis=1)

    # –†–∞–∑–±–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ø–µ–∫—Ç—Ä –Ω–∞ —Ä–∞–≤–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    num_freqs = len(frequencies)
    freq_bins = np.linspace(frequencies[0], frequencies[-1], num=500)

    # –°—É–º–º–∏—Ä—É–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–ª—é–∫—Å –≤ –∫–∞–∂–¥–æ–º —á–∞—Å—Ç–æ—Ç–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
    flux_per_band = []
    for i in range(len(freq_bins) - 1):
        freq_mask = (frequencies >= freq_bins[i]) & (frequencies < freq_bins[i + 1])
        if np.any(freq_mask):
            flux = np.sum(spectral_flux[freq_mask])
            flux_per_band.append((flux, freq_bins[i], freq_bins[i + 1]))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —Ñ–ª—é–∫—Å–∞ (–∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏)
    flux_per_band.sort(reverse=True, key=lambda x: x[0])

    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø `num_bands` –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    top_bands = flux_per_band[:num_bands]

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã
    top_bands.sort(key=lambda x: x[1])

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    suggested_bands = [(round(band[1]), round(band[2])) for band in top_bands]

    print("–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã:")
    for idx, band in enumerate(suggested_bands):
        print(f"–î–∏–∞–ø–∞–∑–æ–Ω {idx+1}: {band[0]} - {band[1]} –ì—Ü")

    return suggested_bands


@prefix_color("MERGE", "bright_black")
def merge_videos_with_audio(
    video_files, audio_file, output_file, profile: Profile, threads=4
):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∫ –Ω–∏–º –∞—É–¥–∏–æ, –∑–∞—Ç–µ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª.

    :param video_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞–º (–±–µ–∑ –∞—É–¥–∏–æ).
    :param audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (MP3).
    :param output_file: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É.
    """
    ice(f"üöÄ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è {len(video_files)} –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤.")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã
    clips = []
    for idx, file in enumerate(video_files):
        ice(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ {idx + 1}/{len(video_files)}: {file}")
        clip = VideoFileClip(file)
        clips.append(clip)

    ice("‚úÖ –í—Å–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã
    ice("üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤...")
    final_clip = concatenate_videoclips(clips, method="compose")
    ice("üé¨ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–æ.")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
    ice(f"üéµ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {audio_file}")
    audio = AudioFileClip(audio_file)
    ice("‚úÖ –ê—É–¥–∏–æ—Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

    # –î–æ–±–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –≤–∏–¥–µ–æ
    ice("üé∂ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ...")
    final_clip = final_clip.set_audio(audio)
    ice("‚úÖ –ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ –≤–∏–¥–µ–æ.")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª
    ice(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {output_file}")
    final_clip.write_videofile(
        output_file, codec=profile.codec, preset=profile.preset, threads=threads
    )
    ice(f"üéâ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")

    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    for file in video_files:
        if os.path.exists(file):
            os.remove(file)
            ice(f"–£–¥–∞–ª—ë–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file}")


def merge_videos(output_file, video_files):

    # folder = 'path/to/your/videos'
    # video_files = sorted([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.mp4')])

    # # Output file path
    # output_file = os.path.join(folder, "merged_output_video.mp4")

    # Load all video clips
    clips = [VideoFileClip(file) for file in video_files]

    # Concatenate all clips into one
    final_clip = concatenate_videoclips(clips, method="compose")

    # Write the result to a file
    final_clip.write_videofile(output_file, codec="libx264", threads=4)


def get_segment_duration(total_duration, segment_number, total_segments):
    # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    segment_length = total_duration // total_segments

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Å–µ–≥–º–µ–Ω—Ç–∞
    start_time = segment_number * segment_length
    end_time = start_time + segment_length

    # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –∫–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
    if segment_number == total_segments + 1:
        end_time = total_duration - 1

    return start_time, end_time

@prefix_color("GIF_ADD", "black")
def add_gif(gif_file, audio_duration, slideshow, resize=1):
    if gif_file and os.path.isfile(gif_file):
        ice("GIF: ‚úîGif file found")

        has_mask = False  # has_transparency(gif_file)
        # –ó–∞–≥—Ä—É–∂–∞–µ–º GIF –∏ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ–º –Ω–∞ –≤—Å—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
        gif_clip = (
            VideoFileClip(gif_file, has_mask)
            .loop(duration=(14.0 * 2.0))  # two times # duration=audio_duration)
            .resize(resize * 0.5)  # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (0.5 = 50% –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞)
            .set_position(("left", "bottom"))
        )  # –ü–æ–∑–∏—Ü–∏—è (–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω—É–∂–Ω—É—é)

        # –î–µ–ª–∞–µ–º —Ñ–æ–Ω GIF –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º (—É–¥–∞–ª—è–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Ü–≤–µ—Ç)
        gif_clip = gif_clip.fx(vfx.mask_color, color=[0, 0, 0], thr=100, s=5)

        inspect_clip("gif_clip", gif_clip)

        # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º GIF –ø–æ–≤–µ—Ä—Ö —Å–ª–∞–π–¥-—à–æ—É
        final_video = CompositeVideoClip([slideshow, gif_clip])
    else:
        final_video = slideshow
    return final_video


def create_slideshow_with_fade_OLD(
    images, audio_duration, image_duration=2, fade_duration=0.1
):
    image_clips = []

    # Create individual image clips with fade in and fade out
    for img in images:
        clip = ImageClip(img).set_duration(image_duration)
        # Apply fade in and fade out effect
        clip = clip.crossfadein(fade_duration).crossfadeout(fade_duration)
        image_clips.append(clip)

    # Concatenate images to form a slideshow
    slideshow = concatenate_videoclips(image_clips, method="compose")

    # Loop the slideshow to match the audio duration
    print(f"SLIDESüñº :: üîÅLooping at ‚åõduration: {audio_duration}")
    looped_slideshow = slideshow.loop(duration=audio_duration)

    return looped_slideshow


@prefix_color("SLIDESüñº", "bright_green")
def create_slideshow_with_fade(
    imageClips: list, audio_duration, image_duration=2, fade_duration=0.1
):
    image_clips = []

    ice(
        f"Total images: {len(imageClips)} :: üîÅLooping at ‚åõduration: {audio_duration:3.0f} secs"
    )
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–ø—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏ –∑–∞—Ç–µ–º–Ω–µ–Ω–∏—è –∏ –ø–æ—è–≤–ª–µ–Ω–∏—è
    for img in imageClips:
        clip = img.set_duration(image_duration)
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –ø–ª–∞–≤–Ω–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –∏ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è
        clip = clip.fadein(fade_duration).fadeout(fade_duration)
        image_clips.append(clip)

    # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–ª–∞–π–¥—à–æ—É
    slideshow = concatenate_videoclips(image_clips, method="compose")

    # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–¥–Ω–æ–≥–æ —Å–ª–∞–π–¥—à–æ—É
    slideshow_duration = slideshow.duration

    # –í—ã—á–∏—Å–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –Ω—É–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —Å–ª–∞–π–¥—à–æ—É
    num_repeats = int(audio_duration // slideshow_duration) + 1

    # –†–∞–∑–º–Ω–æ–∂–∞–µ–º –º–∞—Å—Å–∏–≤ –∫–ª–∏–ø–æ–≤
    replicated_clips = image_clips * num_repeats
    ice(
        f"Replicated images: {len(replicated_clips)} :: üîÅRepeated: {num_repeats} times"
    )

    # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º —Ä–∞–∑–º–Ω–æ–∂–µ–Ω–Ω—ã–µ –∫–ª–∏–ø—ã –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–ª–∞–π–¥—à–æ—É
    full_slideshow = concatenate_videoclips(replicated_clips, method="compose")

    # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∞–π–¥—à–æ—É, —á—Ç–æ–±—ã –æ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ
    final_slideshow = full_slideshow.subclip(0, audio_duration)

    return final_slideshow

def resize_is_needed(clip, target_height):
    if target_height != clip.size[1]:
        clip_resized = clip.resize(height=target_height)
        ice(f"‚ÜîÔ∏è‚ÜïÔ∏èResized : w{clip.size[0]} x h{clip.size[1]} => w{standard_width} x h{standard_height}")
    else:
        clip_resized = clip
    return clip_resized
    

@prefix_color("IMAGE_ADJUST", "blue")
def adjust_image_clips(image_clips, target_height, mode="crop"):
    """
    Adjusts a list of ImageClips to have the same size.

    Parameters:
    - image_clips (list of ImageClip): List of images to process.
    - target_height (int): The target vertical size (height) in pixels.
    - mode (str): Determines how to handle images with differing aspect ratios.
        - 'crop': Crop the images to fit the standard width.
        - 'pad': Pad the images with black bars to fit the standard width.

    Returns:
    - adjusted_clips (list of ImageClip): List of adjusted ImageClips with the same size.
    """
    adjusted_clips = []

    if not image_clips:
        return adjusted_clips  # Return empty list if input is empty

    # Adjust the first image to determine the standard width
    first_clip = image_clips[0]
    first_clip_resized = resize_is_needed(first_clip, target_height)
    standard_width, standard_height = first_clip_resized.size

    # # Process the first clip
    # if mode == 'crop':
    #     # Crop the first clip if necessary (though width should already match standard_width)
    #     first_clip_final = first_clip_resized.crop(width=standard_width, height=target_height)
    # elif mode == 'pad':
    #     # Pad the first clip if necessary (should not be needed for first clip)
    #     first_clip_final = first_clip_resized.on_color(size=(standard_width, target_height),
    #                                                    color=(0, 0, 0),
    #                                                    col_opacity=1)
    # else:
    #     raise ValueError("Invalid mode. Use 'crop' or 'pad'.")

    adjusted_clips.append(first_clip_resized)

    # Process the rest of the images
    for clip in image_clips[1:]:
        # Resize clip to target height while maintaining aspect ratio
        clip_resized = resize_is_needed(clip, target_height)
        clip_width, clip_height = clip_resized.size

        if clip_width > standard_width:
            if mode == "crop":
                # Crop the clip horizontally to match the standard width
                x_center = clip_width / 2
                x1 = x_center - standard_width / 2
                x2 = x_center + standard_width / 2
                clip_final = clip_resized.crop(x1=x1, x2=x2)
                ice(
                    f"Crop to ‚è¨smaller : w{clip_final.size[0]} x h{clip_final.size[1]}"
                )
            elif mode == "pad":
                # Since clip is wider than standard width, we need to crop
                x_center = clip_width / 2
                x1 = x_center - standard_width / 2
                x2 = x_center + standard_width / 2
                clip_final = clip_resized.crop(x1=x1, x2=x2)
                ice(f"Pad to ‚è¨smaller : w{clip_final.size[0]} x h{clip_final.size[1]}")
        elif clip_width < standard_width:
            if mode == "crop":
                # Since clip is narrower than standard width, we need to stretch or pad
                # For crop mode, we can center the clip on a black background
                clip_final = clip_resized.on_color(
                    size=(standard_width, target_height),
                    color=(0, 0, 0),
                    col_opacity=1,
                    pos=("center", "center"),
                )
                ice(f"Crop to ‚è´bigger : w{clip_final.size[0]} x h{clip_final.size[1]}")
            elif mode == "pad":
                # Pad the clip horizontally to match the standard width
                clip_final = clip_resized.on_color(
                    size=(standard_width, target_height),
                    color=(0, 0, 0),
                    col_opacity=1,
                    pos=("center", "center"),
                )
                ice(f"Pad to ‚è´bigger : w{clip_final.size[0]} x h{clip_final.size[1]}")
        else:
            # Width matches the standard width
            clip_final = clip_resized

        adjusted_clips.append(clip_final)

    return adjusted_clips


def inspect_clip(name, clip, debug=False):
    if not debug:
        return

    # Get the size (resolution) of the clip
    print(f"===== Inspect clip: {name} ========")
    size = clip.size
    print(f"Size (width, height): {size}")

    # Get the duration of the clip
    duration = clip.duration
    print(f"Duration: {duration} seconds")

    # Check if the clip has an alpha mask (transparency)
    has_transparency = clip.mask is not None
    print(f"Has transparency (alpha channel): {has_transparency}")

    # Get the number of color channels by inspecting a frame
    frame = clip.get_frame(0)  # Get the first frame of the clip
    num_channels = (
        frame.shape[2] if len(frame.shape) == 3 else 1
    )  # Check if the frame has color channels
    print(f"Number of color channels: {num_channels} (‚Ñπ: 3 for RGB, 4 for RGBA)")

    # Print if the clip has transparency based on number of channels
    if num_channels == 4:
        print("This clip is RGBA (has transparency).")
    else:
        print("This clip is RGB (no transparency).")
    print("==============================")


# Example usage with a clip:
# Assuming you have a clip object
# inspect_clip(clip)


def has_transparency(gif_path):
    img = Image.open(gif_path)
    if img.mode in ("RGBA", "LA") or (img.mode == "P" and "transparency" in img.info):
        return True
    return False


# # Assuming 'final_video' is your video clip and 'audio_duration' is the duration of the audio
# text = "–í–û–¢ –ë–´ –ë–´–õ–ê"  # The text you want to add

# # Add text overlay to the video
# final_video_with_text = add_text_overlay(final_video, text, duration=audio_duration)

# # Save the final video with text
# final_video_with_text.write_videofile("output_with_text.mp4", fps=24)


def add_text_overlay(
    video_clip, text, duration, fontsize=50, color="white", transparency=0.6
):
    # Create the text clip
    text_clip = (
        TextClip(text, fontsize=fontsize, color=color, font="Arial-Bold")
        .set_duration(duration)
        .set_position(
            ("center", "bottom")
        )  # Position at the center bottom of the video
        .set_opacity(transparency)
    )  # Set transparency

    # Overlay the text on the video
    video_with_text = CompositeVideoClip([video_clip, text_clip])

    return video_with_text
