from moviepy.editor import *
import os
import cv2
from console_tools import prefix_color, ice
import equalizers
from model import Profile, TextConfig
import tools

@prefix_color("CONVERTOR", "cyan")
def create_video_from_folder(audio_file, profile: Profile, gif_file=None, part=None, num_cores=1, is_audio=True,
                             output_file=None, colormap = cv2.COLORMAP_JET, image_duration=20, text: TextConfig = None):
    text = text or TextConfig('', True)
    folder = tools.get_directory_from_path(audio_file)
    clip_path = tools.get_directory_from_path(output_file)
    part_str = f"({part})" if part != None else ""
    ice(f"{part_str} :: Start creating from: ðŸ“‚{folder}", )

    # Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ð¿Ð°Ð¿ÐºÐµ
    images = [os.path.join(folder, img) for img in sorted(os.listdir(folder)) \
            if img.endswith(('.png', '.jpg', '.jpeg', '.jfif')) and not img.startswith("frame_")]

    # Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾-Ñ„Ð°Ð¹Ð»Ð°
    audio = AudioFileClip(audio_file)
    audio_duration = audio.duration
    ice(f"{part_str} :: ðŸŽ¶Audio âŒ›duration: {audio_duration} secs")
    
    # tools.suggest_frequency_bands(audio_file)
    
    start, end = 0, audio_duration
    if profile and profile.crop != None and not profile.crop.is_empty():
        start = profile.crop.start
        end = min(profile.crop.end or audio_duration, audio_duration)
        ice(f"{part_str} :: Profile âœ‚ï¸{part}: â± [{start:3.0f}...{end:3.0f}] secs")
    elif part != None:
        start, end = tools.get_segment_duration(audio_duration, part, num_cores)
        ice(f"{part_str} :: Part âœ‚ï¸{part}: â± [{start:3.0f}...{end:3.0f}] secs")

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ»Ð°Ð¹Ð´-ÑˆÐ¾Ñƒ Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð¸ÐµÐ¼ Ð¸ Ð·Ð°Ñ‚ÐµÐ¼Ð½ÐµÐ½Ð¸ÐµÐ¼
    ice(f"{part_str} :: â©Create looping slideshow with fade transition")
    imageClips = [ImageClip(img) for img in images]
        
    target_height = 1024 # None # 
    if profile.resize and profile.resize != 1 and target_height != None:
        target_height *= profile.resize 
        ice(f"{part_str} :: Video resized with factor {profile.resize}. Resulted height will be {target_height}")

    imageClips = tools.adjust_image_clips(imageClips, target_height, mode='crop')
    slideshow = tools.create_slideshow_with_fade(imageClips, audio_duration=audio_duration, 
                                           image_duration=image_duration, fade_duration=0.1)

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ GIF-Ñ„Ð°Ð¹Ð»Ð° Ð¸ Ð½Ð°ÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÐµÐ¼ ÐµÐ³Ð¾ Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾
    final_video = tools.add_gif(gif_file, audio_duration, slideshow, profile.resize)

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ðº Ð²Ð¸Ð´ÐµÐ¾
    final_video = final_video.set_audio(audio)

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐºÐ²Ð°Ð»Ð°Ð¹Ð·ÐµÑ€Ð½Ñ‹Ð¹ ÐºÐ»Ð¸Ð¿
    ice(f"{part_str} :: â©Create equalizer visualization")
    # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð¾Ð² Ñ‡Ð°ÑÑ‚Ð¾Ñ‚ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð¸Ð· Ñ‡ÐµÑ‚Ñ‹Ñ€ÐµÑ… ÑÑƒÐ±-Ñ‚Ð¾Ñ‡ÐµÐº Ñ ÑƒÑÐ¸Ð»ÐµÐ½Ð¸ÐµÐ¼
    frequency_bands = [
        {'band': (20, 80), 'amplification': 2.0},
        {'band': (80, 255), 'amplification': 14.0}, # humain voice band
        {'band': (255, 500), 'amplification': 3.0},
        {'band': (500, 8000), 'amplification': 40.0},
    ]
    # all color maps : https://learnopencv.com/applycolormap-for-pseudocoloring-in-opencv-c-python/
    equalizer_clip = equalizers.create_equalizer_clip(audio_file, duration=audio_duration,
                        size=final_video.size, 
                        colormap=colormap, circle_radius=300 * profile.resize,
                          center_dot_size=35, edge_dot_size=5,
                          colormap_positions=[0.0, 0.33, 0.66, 1.0],
                          num_dots=30,
                          circle_vertical_position_percent=7,
                          amplitude_threshold=0.6,
                          debug_mode=False, fps=profile.fps,
                          frequency_bands=frequency_bands)

    # Ð”ÐµÐ»Ð°ÐµÐ¼ Ñ„Ð¾Ð½ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ñ‹Ð¼ (ÑƒÐ´Ð°Ð»ÑÐµÐ¼ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚)
    equalizer_clip = equalizer_clip.fx(vfx.mask_color, color=[0, 0, 0], thr=100, s=5)   
    equalizer_clip = equalizer_clip.set_opacity(0.2)  # ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾: ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð·Ñ€Ð°Ñ‡Ð½Ð¾ÑÑ‚ÑŒ

    tools.inspect_clip("final_video", final_video)
    tools.inspect_clip("equalizer_clip", equalizer_clip)
    # ÐÐ°ÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÐµÐ¼ ÑÐºÐ²Ð°Ð»Ð°Ð¹Ð·ÐµÑ€ Ð¿Ð¾Ð²ÐµÑ€Ñ… Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ð¸Ð´ÐµÐ¾
    ice(f"{part_str} :: âž•Add equalizer visualization")
    final_video = CompositeVideoClip([final_video, equalizer_clip])

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÐºÐ»Ð¸Ð¿
    # text = """ÐšÐ£Ð”Ð Ð£Ð¥ÐžÐ”Ð¯Ð¢\n\n\nÐ”Ð•ÐÐ¬Ð“Ð˜?"""
    if not text.is_empty():
        font_path = "C:/Users/desktop/AppData/Local/Microsoft/Windows/Fonts/Roboto-Bold.ttf"
        text_clip = tools.create_text_clip(
            text=text.text,
            duration=audio_duration,             # Ð¢ÐµÐºÑÑ‚ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°Ñ‚ÑŒÑÑ 10 ÑÐµÐºÑƒÐ½Ð´
            start_time=0,            # ÐÐ°Ñ‡Ð½ÐµÑ‚ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°Ñ‚ÑŒÑÑ Ñ 5-Ð¹ ÑÐµÐºÑƒÐ½Ð´Ñ‹
            position=("center","center"), # (1, -5),       # ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð°Ñ… (50% Ð¿Ð¾ ÑˆÐ¸Ñ€Ð¸Ð½Ðµ, 80% Ð¿Ð¾ Ð²Ñ‹ÑÐ¾Ñ‚Ðµ)
            position_units=None, # 'percent',
            font=font_path, # 'Arial',
            font_size=120*profile.resize,
            font_color='white', # 'white', 'gray'
            stroke_color='black', # 'black', gray
            stroke_width=3,
            fade_duration=0.5,          # ÐŸÐ»Ð°Ð²Ð½Ð¾Ðµ Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ðµ Ð¸ Ð¸ÑÑ‡ÐµÐ·Ð½Ð¾Ð²ÐµÐ½Ð¸Ðµ Ð² Ñ‚ÐµÑ‡ÐµÐ½Ð¸Ðµ 1 ÑÐµÐºÑƒÐ½Ð´Ñ‹
            video_size=final_video.size
        )
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ
        final_video_with_text = CompositeVideoClip([final_video, text_clip])
        # if part == 1 or part == None:
        #     tools.save_snapshots(final_video_with_text, [1, 5, 11, 32, 63], clip_path)
        # if not text.text_shot:
        #     ice(f"Use text in video: {text.text}")
        final_video = final_video_with_text
    # else:
    #     tools.save_snapshots(final_video, [1, 5, 11, 32, 63], clip_path)

    if start > 0 or end < audio_duration:
        ice(f"{part_str} :: â—â—â— Video croped âœ‚ï¸{start:3.0f}-{end:3.0f}âœ‚ï¸")
        final_video = final_video.subclip(start, end)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾
    final_video.write_videofile(output_file, fps=profile.fps, threads=1, \
        codec=profile.codec, preset=profile.preset, audio=is_audio) # ,bitrate=bitrate
    ice(f"{part_str} :: Video created: {output_file}")
